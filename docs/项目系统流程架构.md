Engram 系统架构：统一记忆流与双阶段处理管道

(Unified Memory Pipeline & Dual-Stage Processing)

1. 核心设计理念

本架构旨在解决角色扮演（RP）场景下，长期记忆构建成本与即时上下文可用性之间的矛盾。

核心策略总结为：

单次提取，多态存储：LLM 仅在总结阶段调用一次，输出结构化 JSON。

双层缓冲机制：

缓冲层 (Buffer)：以渲染后的“人读文本”形态存在于世界书（Worldbook），低成本，即时生效。

归档层 (Archive)：以“向量+图谱”形态存在于数据库，批量处理，用于长期召回。

渲染器模式 (Renderer Pattern)：解耦数据（JSON）与展示（Worldbook Text），确保存储的纯净性与展示的灵活性。

2. 数据模型定义

2.1 LLM 原始输出 (The Raw Extraction)

这是 Prompt 指令要求模型输出的标准 JSON 格式，包含剧情摘要与图谱元数据。

interface PlotExtraction {
  // 核心剧情摘要，用于未来的向量检索
  summary: string;
  
  // 触发 SillyTavern 世界书的关键词
  keywords: string[];
  
  // 剧情发生的时空背景
  timestamp: string; // e.g., "第42天 深夜"
  location: string;  // e.g., "月光酒馆"
  
  // 涉及的实体列表 (用于图谱节点链接)
  entities: Array<{
    name: string;
    type: string; // e.g., "Character", "Item", "Location"
  }>;
  
  // 实体间的关系 (用于构建边)
  relations: Array<{
    subject: string;
    predicate: string;
    object: string;
  }>;
  
  // 额外细节 (可选)
  details?: string;
}


2.2 数据库存储结构 (Unified Event Node)

存入 DexieDB 的统一数据结构。同一条数据在不同生命周期阶段仅改变状态和填充字段。

interface EventNode {
  id: string;             // UUID
  type: 'event_node';
  
  // --- 状态控制 ---
  // buffer: 仅作为世界书条目存在，未向量化
  // archived: 已向量化，已连接到图谱，从活跃世界书中移除/折叠
  status: 'buffer' | 'archived';
  
  // --- 内容数据 ---
  raw_data: PlotExtraction; // 完整保存 LLM 的原始输出
  
  // --- 索引数据 (仅在 archived 状态下有效) ---
  embedding?: number[];     // summary 的向量
  
  // --- 渲染缓存 (可选) ---
  display_text: string;     // 渲染后的文本，用于展示给用户或注入 Context
}


3. 业务流程详解

3.1 阶段一：写入与缓冲 (Ingestion & Buffering)

此阶段的目标是以最低延迟生成可用的世界书条目，不涉及昂贵的向量计算。

触发条件：楼层计数器达到阈值（如每 10-20 条对话）。

LLM 处理：

输入：最近的对话块（Chunk）。

输出：PlotExtraction JSON 对象。

数据分流 (The Split)：

动作 A (渲染)：调用 StoryRenderer.render(json) 将 JSON 转换为 Markdown 格式的卡片文本。

动作 B (存储)：将原始 JSON 和渲染后的文本存入 DexieDB，状态标记为 buffer。

动作 C (同步)：将渲染后的文本和关键词同步到 SillyTavern 的 World Info 系统中（作为一条新的 Entry）。

3.2 阶段二：归档与索引 (Consolidation & Indexing)

此阶段将碎片化的短期记忆固化为长期图谱记忆。

触发条件：

Buffer 中的条目数量达到 N 条（如 10 条）。

Buffer 中的总 Token 数达到阈值。

用户手动点击“整理记忆”。

批处理 (Batch Process)：

读取所有状态为 buffer 的 EventNodes。

向量化：提取 summary 字段，批量调用 Embedding API，生成向量并回填入数据库。

图谱构建：遍历 entities 和 relations，在 Graph Store 中创建/更新实体节点，并建立 Event 到 Entity 的边。

状态变更：

将这些 Nodes 的状态更新为 archived。

UI 更新：在前端“总结世界书”界面中，将这些条目归档（或标记为已索引），不再占用 SillyTavern 的 World Info 额度（或降低优先级）。

3.3 阶段三：检索与增强 (Retrieval & Generation)

意图识别 (Query Expansion)：

分析用户当前输入 + 最近几条历史。

LLM 生成明确的搜索关键词（解决“那件事”指代不明问题）。

混合召回 (Hybrid Search)：

向量路：搜索 EventNode 的 summary 向量。

图谱路：根据关键词定位 EntityNode，获取其属性及关联的 EventNode。

重排序与注入：

对召回结果去重、打分。

将 Top-K 结果注入到 Prompt 的 Context 区域。

4. 关键组件设计

4.1 故事渲染器 (StoryRenderer)

负责将结构化数据“翻译”为沉浸式文本。

class StoryRenderer {
  static render(data: PlotExtraction): string {
    // 示例格式：Markdown 卡片
    return `
---
📅 时间: ${data.timestamp}
📍 地点: ${data.location}
🔑 关键词: ${data.keywords.join(', ')}
---
📜 **事件摘要**:
${data.summary}

> ${data.details || ''}
`.trim();
  }
}


4.2 流程时序图 (Sequence Diagram)

sequenceDiagram
    participant ST as SillyTavern/User
    participant Pipe as Pipeline
    participant LLM as LLM Service
    participant Render as StoryRenderer
    participant DB as DexieDB
    participant Embed as Embedding API

    %% Phase 1
    rect rgb(20, 25, 30)
    Note over ST, DB: 阶段一：缓冲 (Buffer)
    ST->>Pipe: 触发总结 (Input Chat)
    Pipe->>LLM: 请求结构化总结
    LLM-->>Pipe: 返回 JSON (Summary+Entities)
    Pipe->>Render: JSON -> 渲染为文本
    Render-->>Pipe: 返回 Display Text
    Pipe->>DB: 存储 EventNode (Status: buffer)
    Pipe->>ST: 写入 World Info (纯文本)
    end

    %% Phase 2
    rect rgb(25, 30, 40)
    Note over Pipe, Embed: 阶段二：归档 (Archive) - 异步/批量
    Pipe->>DB: 查询 Pending Buffer Items
    DB-->>Pipe: 返回 N 条记录
    Pipe->>Embed: 批量请求 Vectorize (Summaries)
    Embed-->>Pipe: 返回 Vectors
    Pipe->>DB: 1. 更新 Embedding<br/>2. 创建图谱实体与连接<br/>3. Set Status = archived
    end
